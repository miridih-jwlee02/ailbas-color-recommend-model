{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Processing 835 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting labels (train):  10%|█         | 86/835 [08:34<1:14:44,  5.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# 4. 각 split에 대해 실행\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[0;32m---> 86\u001b[0m     extract_labels_and_save(df_split[split], split)\n",
      "Cell \u001b[0;32mIn[8], line 67\u001b[0m, in \u001b[0;36mextract_labels_and_save\u001b[0;34m(df_part, split)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m     66\u001b[0m     image_bytes \u001b[38;5;241m=\u001b[39m img_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 67\u001b[0m labels \u001b[38;5;241m=\u001b[39m detect_labels(image_bytes)\n\u001b[1;32m     68\u001b[0m label_descriptions \u001b[38;5;241m=\u001b[39m [label\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[1;32m     69\u001b[0m labels_collected\u001b[38;5;241m.\u001b[39mextend(label_descriptions)\n",
      "File \u001b[0;32m/workspace/text2palette/color_palette_completion/notebooks/../src/color_palette_completion/utils/image_label_detector.py:8\u001b[0m, in \u001b[0;36mdetect_labels\u001b[0;34m(image_content)\u001b[0m\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mImageAnnotatorClient()\n\u001b[1;32m      7\u001b[0m image \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mImage(content\u001b[38;5;241m=\u001b[39mimage_content)\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mlabel_detection(image\u001b[38;5;241m=\u001b[39mimage, max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \u001b[38;5;66;03m# set topN with max_results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mlabel_annotations\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/vision_helpers/decorators.py:112\u001b[0m, in \u001b[0;36m_create_single_feature_method.<locals>.inner\u001b[0;34m(self, image, max_results, retry, timeout, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     copied_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_results\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_results\n\u001b[1;32m    111\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(image\u001b[38;5;241m=\u001b[39mimage, features\u001b[38;5;241m=\u001b[39m[copied_features], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 112\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotate_image(\n\u001b[1;32m    113\u001b[0m     request, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout, metadata\u001b[38;5;241m=\u001b[39mmetadata\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/vision_helpers/__init__.py:76\u001b[0m, in \u001b[0;36mVisionHelpers.annotate_image\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(request\u001b[38;5;241m.\u001b[39mfeatures) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     request\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_features()\n\u001b[0;32m---> 76\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_annotate_images(\n\u001b[1;32m     77\u001b[0m     requests\u001b[38;5;241m=\u001b[39m[request], retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout, metadata\u001b[38;5;241m=\u001b[39mmetadata\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/vision_v1/services/image_annotator/client.py:548\u001b[0m, in \u001b[0;36mImageAnnotatorClient.batch_annotate_images\u001b[0;34m(self, request, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    545\u001b[0m rpc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39m_wrapped_methods[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mbatch_annotate_images]\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    549\u001b[0m     request,\n\u001b[1;32m    550\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    551\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    552\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m     )\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import ast\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from color_palette_completion.utils.image_label_detector import detect_labels\n",
    "from color_palette_completion.text_color_model.model_config import Config\n",
    "\n",
    "MAX_LABELS = Config['Max_Image_Labels_Length']\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =\"/workspace/text2palette/profound-actor-347102-b0e7c4a8632c.json\"\n",
    "\n",
    "data_path = \"/workspace/text2palette/color_palette_completion/data/t2p/text_miridih\"\n",
    "csv_path = \"/workspace/text2palette/color_palette_completion/data/colors/data_colors_labels/text_palette_extracted.csv\"\n",
    "image_root_path = \"/data/shared/xml_image_csv_converter/image/group_true/total_images\"\n",
    "\n",
    "lang_type = \"_en\"\n",
    "filename_template = f\"image_labels_imagemust_{{}}{lang_type}.txt\"\n",
    "splits = ['train', 'val', 'test']\n",
    "split_ratios = [0.8, 0.1, 0.1]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "total_len = len(df_shuffled)\n",
    "train_end = int(total_len * split_ratios[0])\n",
    "val_end = train_end + int(total_len * split_ratios[1])\n",
    "\n",
    "df_split = {\n",
    "    \"train\": df_shuffled.iloc[:train_end],\n",
    "    \"val\": df_shuffled.iloc[train_end:val_end],\n",
    "    \"test\": df_shuffled.iloc[val_end:]\n",
    "}\n",
    "\n",
    "def extract_labels_and_save(df_part, split):\n",
    "    label_lines = []\n",
    "\n",
    "    print(f\"[{split}] Processing {len(df_part)} rows...\")\n",
    "    for _, row in tqdm(df_part.iterrows(), total=len(df_part), desc=f\"Extracting labels ({split})\"):\n",
    "        image_files = row['image_file_name']\n",
    "        group_key = row['group_key']\n",
    "        group_id, sub_id = group_key.split('_')\n",
    "\n",
    "        # 리스트 문자열이면 파싱\n",
    "        try:\n",
    "            image_files = ast.literal_eval(image_files) if isinstance(image_files, str) and image_files.startswith('[') else [image_files]\n",
    "        except Exception as e:\n",
    "            print(f\"Could not parse image_file_name: {image_files}. Error: {e}\")\n",
    "            image_files = []\n",
    "\n",
    "        labels_collected = []\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(image_root_path, group_id, sub_id, image_file)\n",
    "            try:\n",
    "                with open(image_path, 'rb') as img_file:\n",
    "                    image_bytes = img_file.read()\n",
    "                labels = detect_labels(image_bytes)\n",
    "                label_descriptions = [label.description for label in labels]\n",
    "                labels_collected.extend(label_descriptions)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {image_path}: {e}\")\n",
    "\n",
    "        # 최대 label 수 제한\n",
    "        label_collected_clipped = labels_collected[:MAX_LABELS]\n",
    "        label_lines.append(str(label_collected_clipped))\n",
    "\n",
    "    output_path = os.path.join(data_path, filename_template.format(split))\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for line in label_lines:\n",
    "            f.write(f\"{line}\\n\")\n",
    "    print(f\"[{split}] Saved to {output_path}\")\n",
    "\n",
    "for split in splits:\n",
    "    extract_labels_and_save(df_split[split], split)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
