{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 코드\n",
    ": Pretrained Weight를 기반으로 Top@1 Accuracy를 구하여 논문에 보고된 내용과의 정합성을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 00:32:18.079722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743553938.096784 3687814 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743553938.101961 3687814 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743553938.116981 3687814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743553938.116994 3687814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743553938.116997 3687814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743553938.116998 3687814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-02 00:32:18.121673: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743553941.597471 3687814 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading test dataset...\n",
      "[INFO] Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/1712 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Mask_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Starting inference...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     42\u001b[0m     (\n\u001b[1;32m     43\u001b[0m         batch_x,\n\u001b[1;32m     44\u001b[0m         batch_mlm_mask,\n\u001b[1;32m     45\u001b[0m         batch_mcc_mask,\n\u001b[1;32m     46\u001b[0m         origin_x,\n\u001b[1;32m     47\u001b[0m         batch_segment,\n\u001b[1;32m     48\u001b[0m         batch_padding_mask,\n\u001b[1;32m     49\u001b[0m         batch_text_embed,\n\u001b[1;32m     50\u001b[0m         batch_image_embed,\n\u001b[0;32m---> 51\u001b[0m     ) \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# SavedModel은 TensorFlow모델이기 때문에 입력값은 Tensor여야 함.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     batch_x_tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(batch_x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)\n",
      "File \u001b[0;32m/workspace/text2palette/color_palette_completion/notebooks/../src/color_palette_completion/text_color_model/input_data_generator.py:258\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    256\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size: (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 258\u001b[0m     batch_x, batch_mlm_mask, batch_mcc_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_mask_language_model_data(batch_data)\n\u001b[1;32m    259\u001b[0m     segment_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_segment_inputs(batch_data)\n\u001b[1;32m    260\u001b[0m     padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_padding_mask(batch_data)\n",
      "File \u001b[0;32m/workspace/text2palette/color_palette_completion/notebooks/../src/color_palette_completion/text_color_model/input_data_generator.py:171\u001b[0m, in \u001b[0;36mDataGenerator.make_mask_language_model_data\u001b[0;34m(self, batch_token_id)\u001b[0m\n\u001b[1;32m    169\u001b[0m         position \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask_position\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;66;03m# 50%의 확률없이, 지정한 위치를 모두 마스킹.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     r_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask_num\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask_num\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(real_seq) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(real_seq)\n\u001b[1;32m    172\u001b[0m     position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(real_seq, size\u001b[38;5;241m=\u001b[39mr_size, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Mask_num'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from color_palette_completion.text_color_model.input_data_generator import DataGenerator\n",
    "from color_palette_completion.text_color_model.model_config import Config\n",
    "\n",
    "Config_pred = Config.copy()\n",
    "Config_pred['Dataset_Type'] = 'test'\n",
    "Config_pred['Batch_Size'] = 1\n",
    "representation = Config_pred['representation']\n",
    "Config_pred['representation'] = representation\n",
    "\n",
    "# 모델 경로 및 불러오기\n",
    "model_path = '/workspace/text2palette/color_palette_completion/data/trained_model/t2p_ca1_mca1_i10t_stop30_lr0.0002__clip_512d_lab_bins_16_0.4_0.5_0'\n",
    "\n",
    "print(\"[INFO] Loading model...\")\n",
    "model = tf.saved_model.load(model_path)\n",
    "\n",
    "serving_signature = model.signatures['serving_default']\n",
    "# print(\"출력 텐서:\", list(serving_signature.structured_outputs.keys()))\n",
    "\n",
    "# # 모델 불러온 후 서명 확인\n",
    "# print(\"모델 서명:\", list(model.signatures.keys()))\n",
    "# serving_key = list(model.signatures.keys())[0]  # 일반적으로 \"serving_default\"\n",
    "# print(\"입력 텐서:\", list(model.signatures[serving_key].structured_input_signature[1].keys()))\n",
    "\n",
    "print(\"[INFO] Loading test dataset...\")\n",
    "dataset = DataGenerator(Config_pred)\n",
    "id2vocab = dataset.corpus.id2vocab\n",
    "vocab2id = dataset.corpus.vocab2id\n",
    "\n",
    "gt_color_list = []\n",
    "pred_color_list = []\n",
    "\n",
    "print(\"[INFO] Starting inference...\")\n",
    "for i in tqdm(range(len(dataset)), desc=\"Inference\"):\n",
    "    (\n",
    "        batch_x,\n",
    "        batch_mlm_mask,\n",
    "        batch_mcc_mask,\n",
    "        origin_x,\n",
    "        batch_segment,\n",
    "        batch_padding_mask,\n",
    "        batch_text_embed,\n",
    "        batch_image_embed,\n",
    "    ) = dataset[i]\n",
    "\n",
    "    # SavedModel은 TensorFlow모델이기 때문에 입력값은 Tensor여야 함.\n",
    "    batch_x_tf = tf.convert_to_tensor(batch_x, dtype=tf.int64)\n",
    "    batch_mlm_mask_tf = tf.convert_to_tensor(batch_mlm_mask, dtype=tf.float32)\n",
    "    batch_segment_tf = tf.convert_to_tensor(batch_segment, dtype=tf.int64)\n",
    "    batch_text_embed_tf = tf.convert_to_tensor(batch_text_embed, dtype=tf.float32)\n",
    "    batch_image_embed_tf = tf.convert_to_tensor(batch_image_embed, dtype=tf.float32)\n",
    "\n",
    "    # 서명 기반 호출 사용\n",
    "    output = serving_signature(\n",
    "        input_1=batch_x_tf,\n",
    "        input_2=batch_mlm_mask_tf,\n",
    "        input_3=batch_segment_tf,\n",
    "        input_4=batch_text_embed_tf,\n",
    "        input_5=batch_image_embed_tf\n",
    "    )\n",
    "\n",
    "    mlm_logits = output['output_1'].numpy()  # (1, 18, vocab_size) # B, S, Vocab_size\n",
    "    mlm_mask = batch_mlm_mask[0]             # (18,)\n",
    "    origin_tokens = origin_x[0]              # (18,)\n",
    "\n",
    "    for pos in np.where(mlm_mask == 1)[0]:\n",
    "        pred_token_id = np.argmax(mlm_logits[0][pos])\n",
    "        gt_token_id = origin_tokens[pos]\n",
    "\n",
    "        pred_token = id2vocab[pred_token_id]\n",
    "        gt_token = id2vocab[gt_token_id]\n",
    "\n",
    "        pred_color_list.append(pred_token)\n",
    "        gt_color_list.append(gt_token)\n",
    "\n",
    "# ✅ Accuracy 계산\n",
    "acc = accuracy_score(gt_color_list, pred_color_list)\n",
    "print(f\"\\n✅ MLM prediction Accuracy@1 on masked tokens: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 12,  13,  64,   8,  10,   0,  80, 141,  18,   2,   2,   0, 141,\n",
      "         18,   2,   2,   2,   0]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[ 12,  13,  64,   8,  10,   0,  80, 141,  18,   2,   2,   0, 141,\n",
      "         18,   2,   2,   2,   0]]), array([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0]]), array([[[ 0.03081548, -0.00844604,  0.00122443, ..., -0.01502745,\n",
      "          0.04747449,  0.00935382],\n",
      "        [ 0.01672275, -0.02535274, -0.00559235, ...,  0.02505554,\n",
      "          0.00573809,  0.02059767],\n",
      "        [-0.00879186, -0.03690744,  0.02558524, ..., -0.04849922,\n",
      "         -0.01688528, -0.02458045],\n",
      "        ...,\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.01685208, -0.01059829, -0.01956167, ...,  0.02544961,\n",
      "          0.02611271,  0.00784868]]]), array([[[-0.00883571, -0.00653027,  0.02992723, ...,  0.00583429,\n",
      "          0.02559909, -0.00189084],\n",
      "        [-0.00991209, -0.03365931, -0.03057194, ...,  0.00160897,\n",
      "         -0.00491832,  0.02992196],\n",
      "        [ 0.01336385, -0.03641503,  0.00444683, ..., -0.01795074,\n",
      "         -0.03139629,  0.0310228 ],\n",
      "        ...,\n",
      "        [-0.01097956, -0.06718635, -0.0355016 , ...,  0.01653968,\n",
      "          0.00415021,  0.01919435],\n",
      "        [ 0.02621984, -0.04317455,  0.00453556, ...,  0.03087592,\n",
      "          0.01282773, -0.02035271],\n",
      "        [ 0.01552873, -0.00533937,  0.01767327, ..., -0.01654051,\n",
      "          0.0246568 , -0.02397495]]]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
